#problemas q ultilizam dados sequenciais
 
#usam loops ou repitiÃ§Ãµes que permitem que a informaÃ§Ã£o persista

#tipo se vc so usa funÃ§Ã£o d ativaÃ§Ã£o e passa o valor pra frente vc n ta armazenando nada

#a descida do gradiente n funciona em redes neurais recorrentes pois ele vai ficando cada vez menor
#atÃ© chegar ao ponto q ele quase n altera o valor dos peso
#nÃ£o consegue armazenar dados muito distantes no tempo

#ai pra resolver isso existe Long Short Term Memory(LSTM)
#que ao ivez d sÃ³ passar a informaÃ§Ã£o pra frente faz (matematica) nos dados
#ai ele usa tanh + (matematica) e da certo ğŸ˜ğŸ˜ğŸ˜
